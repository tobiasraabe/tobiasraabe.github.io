{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Why should I use them\n",
    "\n",
    "Both decorators are extremely powerful as Numba compiles the instructions of the decorated function to machine code which makes them significantly faster than the same operation written with Numpy. Of course, this is also true for functions decorated with ``@jit``, but the other two decorators enable other features like reduction, accumulation and broadcasting ([explanation](#Example-for-reduction,-accumulation-and-broadcasting)) which make operations on big matrices even faster.\n",
    "\n",
    "### When should I use them\n",
    "\n",
    "The root of all evil is pre-mature optimization. Before you start to optimize your implementation use tools like [line_profiler](https://github.com/rkern/line_profiler) or [snakeviz](https://github.com/jiffyclub/snakeviz) to profile your code and find perfomance bottlenecks. Often it is sufficient to find better implementations from the standard library or rewrite parts such that they use Numpy or similar optimised frameworks. If you use Numpy, do not use loops but array operations. Use higher-dimensional arrays to gain performance by broadcasting. [Avoid copies]({filename}/Blog/numpy-views-vs-copies.md). Also refactoring and rewriting parts of the code may not give direct speed improvements, but your code becomes more compact and you can single out expensive operations.\n",
    "\n",
    "Imagine you have done all this, but still there are some functions which take up the majority of runtime. Then, decide whether you need a function that operates on single elements or on arrays.\n",
    "\n",
    "### Using the ``@vectorize`` decorator\n",
    "\n",
    "The ``@vectorize`` is for writing efficient functions which work on every element of an array. One useful application for me was to compute the probability of ``x`` under a normal distribution with mean ``mu`` and standard deviation ``sigma``. There already exists an implemenation in scipy, but it was too slow in my case. Let us start to write the function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "def get_prob_norm_dist(x, mu=0, sigma=1):\n",
    "    return 1 / (np.sqrt(2 * np.pi) * sigma) * np.exp(-(x - mu) ** 2 / (2 * sigma ** 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can check our implementation against the scipy version to make sure it works as expected. Use the testing utilities from ``numpy.testing`` as the precision of the returns can differ because of the implementation or the underlying dependencies. (Tip: Use [doctest](https://docs.python.org/3.7/library/doctest.html) to document and test your function at the same time. [Here is an example](#Example-using-doctest).)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import norm\n",
    "\n",
    "np.random.seed(42)\n",
    "\n",
    "a = np.random.randn(10)\n",
    "\n",
    "np.testing.assert_array_almost_equal(norm.pdf(a), get_prob_norm_dist(a), decimal=15)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, create test data and measure the performance of our two methods."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.random.randn(10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "616 µs ± 117 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit norm.pdf(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "89.8 µs ± 19.7 µs per loop (mean ± std. dev. of 7 runs, 10000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_prob_norm_dist(a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Surprisingly, we are already faster by a factor of 8. At this point you should ask yourself again if further optimization is really necessary and whether your time is better spent anywhere else. But, in this example we want to go down the rabbit hole a little bit further. The next step involves rewriting the function with the ``@vectorize`` decorator.\n",
    "\n",
    "The major new thing is that the decorator requires a signature or even multiple signatures which define the input and output types of the function. The output type wraps the input types with round brackets. There are two ways to define the signature: declare the types of the arguments with types from Numba or declare the types with a string. I prefer the latter as it keeps your import statements short. With ``nopython=True``, Numba does not use Python as a fallback if compilation fails, so we get notified. Also, the new function does not like our default arguments."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import vectorize\n",
    "\n",
    "@vectorize([\"float64(float64, float64, float64)\"], nopython=True)\n",
    "def get_prob_norm_dist_fast(x, mu, sigma):\n",
    "    return 1 / (np.sqrt(2 * np.pi) * sigma) * np.exp(-(x - mu) ** 2 / (2 * sigma ** 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "292 µs ± 28.4 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_prob_norm_dist_fast(a, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The new version actually requires three times the runtime of the Numpy version. But, while using Numba we need to code a little bit different. As appealing the one-liner may look, Numba works better if we store intermediate results in other variables and combine them later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "@vectorize([\"float64(float64, float64, float64)\"], nopython=True, target=\"cpu\")\n",
    "def get_prob_norm_dist_fast(x, mu, sigma):\n",
    "    y = x - mu\n",
    "    \n",
    "    a = np.sqrt(2 * np.pi) * sigma\n",
    "    b = np.exp(-y ** 2 / (2 * sigma ** 2))\n",
    "\n",
    "    probability = 1 / a * b\n",
    "\n",
    "    return probability"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "309 µs ± 19.7 µs per loop (mean ± std. dev. of 7 runs, 1000 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_prob_norm_dist_fast(a, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The extra speed is negligible, but this is just a showcase. If the operation does not involve many calculations and the input is not big, you cannot expect more performance than plain Numpy. If we increase the number of calculations and set the ``target`` keyword from ``cpu`` to ``parallel``, we get similar performances.\n",
    "\n",
    "The different target means that the compiled function does not use one core, but a recommended amount of cores on your machine."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = np.random.randn(10000, 10000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4.89 s ± 133 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_prob_norm_dist_fast(x, 0, 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.85 s ± 79 ms per loop (mean ± std. dev. of 7 runs, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%timeit get_prob_norm_dist(x, 0, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even if the resulting function is slower than the Numpy implementation, it can still make sense to write one. For example, you can only use a function inside a Numba-compiled function if the same function is also compiled. When this [PR for Numba](https://github.com/numba/numba/pull/2469) is finished, nesting functions is no obstacle anymore, but until then it is not possible all the time. Also, Numba [inlines functions](https://numba.pydata.org/numba-doc/dev/user/faq.html#does-numba-inline-functions) which means the function and its calls are compiled as one function. So, you do not have to worry whether calling another function reduces performance.\n",
    "\n",
    "### Using the ``@guvectorize`` decorator\n",
    "\n",
    "I found the ``@guvectorize`` extremely useful and powerful, but at the same time hard to understand as I was not really experienced in the more general concepts of array computation. The following example is a Monte Carlo integration with which I understand gradually more and more of this approach.\n",
    "\n",
    "The hardest part to understand for me was what extrapolating from arrays to arrays of higher dimension means. Therefore, we will start with the simplest example and then gradually expand the problem. Along the way, will notice that the gufunc does not need to be changed.\n",
    "\n",
    "The problem is that we have an agent faced with four choices which yield constant utilities plus a stochastic component which is i.i.d. and normally distributed. We want to find the expected maximum utility (emax) from all choices which can be simulated by calculating maximum utility for a number of draws. The average yields the emax."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "np.random.seed(42)\n",
    "static_utilities = np.arange(1, 5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1. Simulate emax for one agent with Numpy\n",
    "\n",
    "We start by simulating emax for one agent with Numpy just to solve the problem the normal way. We create 1000 draws add them to the deterministic component of the utility, take the max and then the average."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_draws = 1000\n",
    "draws = np.random.randn(num_draws, 4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_emax_np(static_utilities, draws):\n",
    "    utilities = static_utilities + draws\n",
    "    max_utilities = utilities.max(axis=1)\n",
    "    emax = max_utilities.mean()\n",
    "    return emax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.247215674679622"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "simulate_emax_np(static_utilities, draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2. Simulate emax for one agent with Numba\n",
    "\n",
    "Now, we will do the same thing with Numba. I will give you the function first and then we will discuss its components."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from numba import guvectorize\n",
    "\n",
    "\n",
    "@guvectorize(\n",
    "    [\"f8[:], f8[:, :], f8[:]\"], \"(n), (p, n) -> ()\", nopython=True, target=\"cpu\"\n",
    ")\n",
    "def simulate_emax(static_utilities, draws, emax):\n",
    "    num_draws, num_choices = draws.shape\n",
    "    emax_ = 0\n",
    "\n",
    "    for i in range(num_draws):\n",
    "        max_utility = 0\n",
    "        for j in range(num_choices):\n",
    "            utility = static_utilities[j] + draws[i, j]\n",
    "\n",
    "            if utility > max_utility or j == 0:\n",
    "                max_utility = utility\n",
    "\n",
    "        emax_ += max_utility\n",
    "\n",
    "    emax[0] = emax_ / num_draws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4.247215674679617"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "emax = simulate_emax(static_utilities, draws)\n",
    "emax"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will look at the decorator and the two new components.\n",
    "\n",
    "1. The first argument is the signature, a list containing type declarations of the inputs. ``f8`` is just short-hand for ``float64`` and ``f8[:]`` represents an one-dimensional, ``f8[:, :]`` a two-dimensional array ([types and signatures](https://numba.pydata.org/numba-doc/dev/reference/types.html)). Note that the output type does not wrap the input types. Instead it is added to the end of the list. Furthermore, this function should return a scalar which has to be declared as an array in the signature. Later, we will only write to the first entry of the array.\n",
    "2. The second argument is the layout which specifies the dimension of the inputs. You can use an arbitrary letter for a dimension, but assign the same letter to dimensions which should match. ``()`` represents a scalar and ``(p, n)`` an array where the first dimension is of size p and the second of size n. The return argument is separated from the rest with an arrow, ``->``. Here the return is declared as a scalar.\n",
    "\n",
    "Now, we will examine the function. In the special case of gufuncs, the return value is added to the arguments of the function.\n",
    "\n",
    "Instead of array operations, we are very explicit within the function and do everything with loops. For each set of draws, we add the deterministic and stochastic components and save only the maximum which is saved to a temporary variable. In the end, the average over the sum of maximum utilities is saved to the initial slot of the output array to get a scalar output.\n",
    "\n",
    "The clumsy syntax helps Numba optimize the syntax. As before, use also temporary variables.\n",
    "\n",
    "#### 3. Simulate emax for many agents and many draws\n",
    "\n",
    "The power of the gufunc is visible if we apply the function to many agents. This is possible without further adjustments as the implementation automatically infers that the defined operation has to be repeated over all other dimensions.\n",
    "\n",
    "Note that, we use the same draws for all individuals."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_agents = 500\n",
    "static_utilities = np.tile(np.arange(1, 5), (num_agents, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unfortunately, we have to adjust the Numpy function as it cannot handle the new dimension. The gufunc is just fine ;). Let's timeit!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def simulate_emax_np(static_utilities, draws):\n",
    "    utilities = static_utilities.reshape(-1, 1, 4) + draws\n",
    "    max_utilities = utilities.max(axis=2)\n",
    "    emax = max_utilities.mean(axis=1)\n",
    "    return emax"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41.3 ms ± 927 µs per loop (mean ± std. dev. of 7 runs, 10 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit simulate_emax_np(static_utilities, draws)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3.04 ms ± 91.1 µs per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit simulate_emax(static_utilities, draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is the magic of the gufunc. You only have to define what should happen with the innermost dimensions and the function will recognize that the operations should be repeated for all other dimensions.\n",
    "\n",
    "Just to make the point, assume that we do the operation for 500 individuals in five villages. So we add another dimension on the left side of the static utilities. Here is only the case for the gufunc because I do not want to adjust the Numpy function again."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_villages = 5\n",
    "static_utilities = np.tile(np.arange(1, 5), (num_villages, num_agents, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "15.7 ms ± 1.13 ms per loop (mean ± std. dev. of 7 runs, 100 loops each)\n"
     ]
    }
   ],
   "source": [
    "%timeit simulate_emax(static_utilities, draws)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Conclusion\n",
    "\n",
    "I have illustrated how ``@vectorize`` and ``@guvectorize`` decorators work and in which settings they can be applied. I omitted ``@jit`` because it is easy to understand with the documentation and does not require much knowledge besides basic Numpy. But also, the subset of supported functions and/or its keywords is so restricted, it was not really useful to me. I achieved major performance boosts with the presented decorators and would recommend to use them. If you find something helpful which is not covered here but suits the topic, write me an email.\n",
    "\n",
    "### Appendix\n",
    "\n",
    "#### More information on Numba\n",
    "\n",
    "- It is also possible to set ``target=\"cuda\"`` and transfer the computation to the processor of your graphic card, GPU. This can provide better performance if the arithmetic intensity per byte transfered to the GPU is sufficiently high. What does that mean? There is an additional overhead to run the function on the GPU instead on CPU (the processors of the computer) which is the transfer of the data. The function can only make up for the additional cost, if there are enough operations on each byte. I read somewhere that you need at least 10 arithmetic operations per byte as a rule of thumb. (More information: [here](https://stackoverflow.com/questions/52046102/numba-and-guvectorize-for-cuda-target-code-running-slower-than-expected/52132523#52132523) and [here](https://stackoverflow.com/questions/49646182/numba-vectorize-for-cuda-what-is-the-correct-signature-to-return-arrays/49661183#49661183).)\n",
    "\n",
    "#### Example for reduction, accumulation and broadcasting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from numba import vectorize\n",
    "\n",
    "@vectorize([\"int32(int32, int32)\", \"int64(int64, int64)\"])\n",
    "def f(x, y):\n",
    "    return x + y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  5,  6,  7],\n",
       "       [ 8,  9, 10, 11]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.arange(12).reshape(3, 4)\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12, 15, 18, 21])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.reduce(a, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([ 6, 22, 38])"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.reduce(a, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  2,  3],\n",
       "       [ 4,  6,  8, 10],\n",
       "       [12, 15, 18, 21]])"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.accumulate(a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0,  1,  3,  6],\n",
       "       [ 4,  9, 15, 22],\n",
       "       [ 8, 17, 27, 38]])"
      ]
     },
     "execution_count": 30,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "f.accumulate(a, axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Broadcasting is a complicated but fundamentally useful concept to understand when writing Numba (g)ufuncs. It is about how Numpy treats two arrays of different shapes while performing arithmetic operations. The simplest example is the following."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = np.array([1, 2, 3])\n",
    "b = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 4, 6])"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obviously, the shapes of the two arrays do not match, but still the result is what we would expect namely that b is applied to each element of a. This also works for higher dimensional structures."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]],\n",
       "\n",
       "       [[1., 1., 1., 1., 1.],\n",
       "        [1., 1., 1., 1., 1.]]])"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = np.ones((2, 2, 5))\n",
    "a"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 2, 2, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "b = np.full((5), 2)\n",
    "b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.]],\n",
       "\n",
       "       [[2., 2., 2., 2., 2.],\n",
       "        [2., 2., 2., 2., 2.]]])"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a * b"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see that the array ``b`` is applied to every other dimension which is not part of ``b`` itself. The general rule behind broadcasting is that when operating on two arrays, Numpy compares their shapes element-wise. It starts with the trailing dimensions, and works its way forward. Two dimensions are compatible when\n",
    "\n",
    "1. they are equal, or\n",
    "2. one of them is 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Example using doctest\n",
    "\n",
    "We extend the function by writing an example in the docstring. Then, we run doctest which executes the example and checks whether outputs match. Note that doctest does not work for gufuncs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_prob_norm_dist(x, mu=0, sigma=1):\n",
    "    \"\"\"Get probability of ``x`` under the normal distribution.\n",
    "    \n",
    "    Example\n",
    "    -------\n",
    "    The second test will fail!\n",
    "    \n",
    "    >>> from scipy.stats import norm\n",
    "    >>> norm.pdf(0)\n",
    "    0.3989422804014327\n",
    "    >>> get_prob_norm_dist(0)\n",
    "    0.3989422804014328\n",
    "    \n",
    "    \"\"\"\n",
    "    return (\n",
    "        1 /\n",
    "        (np.sqrt(2 * np.pi) * sigma) *\n",
    "        np.exp(-(x - mu) ** 2 / (2 * sigma ** 2))\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "**********************************************************************\n",
      "File \"__main__\", line 11, in __main__.get_prob_norm_dist\n",
      "Failed example:\n",
      "    get_prob_norm_dist(0)\n",
      "Expected:\n",
      "    0.3989422804014328\n",
      "Got:\n",
      "    0.3989422804014327\n",
      "**********************************************************************\n",
      "1 items had failures:\n",
      "   1 of   3 in __main__.get_prob_norm_dist\n",
      "***Test Failed*** 1 failures.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "TestResults(failed=1, attempted=3)"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import doctest; doctest.testmod()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
