{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In one of my recent projects on natural language processing and patents,\n",
    "I tried to program a little script which downloads files needed for the\n",
    "analysis.\n",
    "\n",
    "The program should be able to do the following things:\n",
    "\n",
    "1. Download a given file\n",
    "2. Resume the download if the file is incomplete\n",
    "3. Validate the file at the end of the download using hashes\n",
    "4. Wrap everything with beautiful progress bars\n",
    "\n",
    "Note that, to run the script you have to have at least a python 3.6 environment as I am using [``f-strings``](https://www.python.org/dev/peps/pep-0498/).\n",
    "\n",
    "### Downloading files\n",
    "\n",
    "At first, we need to know how to download a file. We will use\n",
    "[``requests``](http://docs.python-requests.org/en/latest/) to handle\n",
    "connections to web content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import requests"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In the next step, we will download a file and store it on the disk. The file size is 19kb, so you are safe to download it. If you have doubts about the file, insert any other link which can be a picture or something else."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.patentsview.org/data/20171226/cpc_group.tsv.zip'\n",
    "\n",
    "r = requests.get(url)\n",
    "\n",
    "with open('cpc_group.tsv.zip', 'wb') as f:\n",
    "    f.write(r.content)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that ``requests.get`` will download the file immediately and store it in memory. For larger files, this does not work as they might not fit in memory. Therefore, we use the ``stream`` keyword to receive the file in chunks and store them on disk. The next file is about 3MB big. Use a different URL if you feel more comfortable with that."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "url = 'http://www.patentsview.org/data/20171226/government_interest.tsv.zip'\n",
    "\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "with open('government_interest.tsv.zip', 'wb') as f:\n",
    "    for chunk in r.iter_content(32 * 1024):\n",
    "        f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Resuming downloads\n",
    "\n",
    "If you download large files, chances are that your download is interrupted. For that, we need a way to resume the download at the last byte position. We can do that by sending a Range-request to the server and specifying the range of bytes, we want to receive."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_header = ({'Range': f'bytes=0-2000000'})\n",
    "\n",
    "r = requests.get(url, stream=True, headers=resume_header)\n",
    "\n",
    "with open('government_interest_part.tsv.zip', 'wb') as f:\n",
    "    for chunk in r.iter_content(32 * 1024):\n",
    "        f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We look at the file size whether we have been able to download the file partially."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Size of file: 2000001 Bytes\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "\n",
    "path = Path('government_interest_part.tsv.zip')\n",
    "\n",
    "print(f'Size of the file: {path.stat().st_size} Bytes')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, we resume the download at the position of the last byte. We also have to change the mode from ``open()`` to ``'ab'`` as we are appending new content and do not want to overwrite existing content."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "resume_header = ({'Range': f'bytes={path.stat().st_size}-'})\n",
    "\n",
    "r = requests.get(url, stream=True, headers=resume_header)\n",
    "\n",
    "with open('government_interest_part.tsv.zip', 'ab') as f:\n",
    "    for chunk in r.iter_content(32 * 1024):\n",
    "        f.write(chunk)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The crucial aspect of this code is that we correctly define the following range of bytes for the following downloads. It is important to know that the boundaries of the Range header are inclusive so that bytes in positions 0 and 2000000 are downloaded. Therefore, the file size is 2000001 and we can plug in the value to correctly resume the download."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Validating downloads\n",
    "\n",
    "At last, we want to make sure that the download of the file worked as expected. To assert whether two files are identical, one of the easiest solutions is to compare hashes. A hash function projects any kind of data onto data with fixed-length. The resulting object is called hash and should be different for two different objects but identical for the same. In this example, we use SHA256 to validate the two files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42e53da0f2adc03e035eb2f967998da5cb8e2b1235cd2630efc59e31df866372\n"
     ]
    }
   ],
   "source": [
    "import hashlib\n",
    "\n",
    "with open('government_interest.tsv.zip', 'rb') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "sha = hashlib.sha256()\n",
    "\n",
    "sha.update(content)\n",
    "\n",
    "print(sha.hexdigest())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42e53da0f2adc03e035eb2f967998da5cb8e2b1235cd2630efc59e31df866372\n"
     ]
    }
   ],
   "source": [
    "with open('government_interest_part.tsv.zip', 'rb') as f:\n",
    "    content = f.read()\n",
    "    \n",
    "sha = hashlib.sha256()\n",
    "\n",
    "sha.update(content)\n",
    "\n",
    "print(sha.hexdigest())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Both hashes match and we have correctly resumed the download :)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Visualizing download progress\n",
    "\n",
    "There are multiple options to print pretty progress bars in python to the command line interface ([``progressbar2``](https://github.com/WoLpH/python-progressbar) e.g.), but I used ``tqdm`` for unknown reasons.\n",
    "\n",
    "To display the progress of the download, we have to know the total file size which we can easily request without downloading the whole file. Use ``requests.head()`` instead of ``requests.get()``."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3895459\n"
     ]
    }
   ],
   "source": [
    "url = 'http://www.patentsview.org/data/20171226/government_interest.tsv.zip'\n",
    "\n",
    "r = requests.head(url)\n",
    "\n",
    "file_size = int(r.headers.get('content-length', 0))\n",
    "\n",
    "print(f'Size of file: {file_size}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note that content length returns a string and not a number."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "government_interest.tsv.zip: 100%|#################################################| 3.71M/3.71M [00:26<00:00, 254kB/s]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "r = requests.get(url, stream=True)\n",
    "\n",
    "initial_pos = 0\n",
    "\n",
    "with open('government_interest.tsv.zip', 'wb') as f:\n",
    "    with tqdm(total=file_size, unit='B',\n",
    "              unit_scale=True, unit_divisor=1024,\n",
    "              desc='government_interest.tsv.zip', initial=initial_pos,\n",
    "              ascii=True, miniters=1) as pbar:\n",
    "        for chunk in r.iter_content(32 * 1024):\n",
    "            f.write(chunk)\n",
    "            pbar.update(len(chunk))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Complete script\n",
    "\n",
    "At last, here is the complete script.\n",
    "\n",
    "<script src=\"https://gist.github.com/tobiasraabe/58adee67de619ce621464c1a6511d7d9.js\"></script>"
   ]
  }
 ],
 "metadata": {
  "front-matter": {
   "date": "2018-06-11",
   "slug": "how-to-download-files-with-python",
   "subtitle": "Generic subtitle",
   "title": "How to download files with Python",
   "toc": "true"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
